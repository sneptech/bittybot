---
phase: 01-inference-spike
task: 3
total_tasks: 3
status: near_complete
last_updated: 2026-02-25T14:30:00Z
---

<current_state>
Plan 01-05 (on-device hardware verification) is nearly complete. All infrastructure tests PASS. The multilingual quality test is running on-device (~30-60 min runtime). The Phase 1 spike goal is achieved: Cohere2 architecture loads and generates text on-device via llama_cpp_dart.
</current_state>

<completed_work>

- Plans 01-01 through 01-04: Complete (SUMMARYs exist)
- MOW migration: GSD -> Mowism completed (commit cd676ee)
- **libmtmd.so rebuilt with static linking** — single self-contained .so, 5MB stripped
- **4 bugs fixed in ModelLoader and test harness:**
  1. `14b6c73` — Load directly from /data/local/tmp/ without copying 2.14 GB (copy failed silently)
  2. `d7ebbfa` — Set mainGpu=-1 for CPU-only mode (llama.cpp validates main_gpu against GPU device count; with 0 devices, main_gpu=0 fails: "invalid value for main_gpu: 0 (available devices: 0)")
  3. `d238c3b` — Share single model instance across tests via setUpAll/tearDownAll (loading 2 GB model twice on 4 GB device caused OOM kill)
  4. `fa6e52d` — Call clear() between generations to reset 512-token context window (without reset, successive prompts accumulated tokens and later prompts got truncated)

- **spike_binding_load_test.dart: 3/3 PASSED**
  - Tiny Aya Global Q4_K_M loads without architecture error
  - Model generates non-empty text from a simple English prompt (~44s generation)
  - Model handles Aya chat template format (Spanish translation, ~2s)

- **spike_streaming_test.dart: 3/3 PASSED**
  - Tokens arrive one-at-a-time during generation (not buffered) — timestamps span generation time
  - Streaming produces output (Japanese "hello world")
  - Token generation speed: 7 tokens in 3877ms = 1.8 tokens/sec; Thai script detected

- **spike_multilingual_test.dart: IN PROGRESS** (running on-device, ~30-60 min total)
  - Mandarin: FAILED (model echoed English "How do I get to the airport?" instead of translating — model quality issue, not infrastructure)
  - Cantonese: IN PROGRESS
  - Remaining: 2 more priority languages + ~66 standard languages

**Key metrics from Galaxy A25 (SM-A256E):**
- Model: Tiny Aya Global 3.35B Q4_K_M (2.14 GB GGUF)
- Architecture: cohere2, Tokenizer: tiny_aya, Vocab: 262144
- Load time: ~10s (warm/cached) / ~85s (cold)
- RAM usage: 2033 MB model + 27 MB KV cache + 260 MB compute = ~2.3 GB
- Inference speed: ~1.8 tokens/sec on ARM Cortex-A78
- No memory pressure crashes on 4 GB device

</completed_work>

<remaining_work>

- Wait for spike_multilingual_test.dart to complete on device
- Retrieve spike_results.json from device (written by ReportWriter in tearDownAll)
- Run judge tooling if desired (tool/judge_quick.dart, tool/judge_full.dart)

</remaining_work>

<decisions_made>

- Built llama.cpp from latest master (commit 2446419, 2026-02-25) — has both Cohere2 AND tiny_aya tokenizer
- Static linking approach confirmed working: single libmtmd.so with no external deps
- llama_cpp_dart 0.2.2 FFI struct definitions match latest llama.cpp (no patching needed)
- NDK 29.0.14033849 used for cross-compile (16KB alignment confirmed)
- OpenMP disabled (GGML_OPENMP=OFF) to avoid __kmpc symbol issues
- Model loads from /data/local/tmp/ directly (no copy to app documents)
- mainGpu=-1 required for CPU-only builds (ModelParams default mainGpu=0 is invalid with 0 GPU devices)
- Llama.clear() needed between prompts to avoid context window accumulation
- Model instances must be shared (not per-test) on memory-constrained devices

</decisions_made>

<blockers>
None — all blockers resolved.
</blockers>

<context>
The Galaxy A25 (SM-A256E, R5CY22C2W0Z) is connected via USB, ADB working. Model file confirmed at /data/local/tmp/tiny-aya-global-q4_k_m.gguf (2,143,977,056 bytes).

All code changes are on the `mowismtest` branch (4 commits ahead of master).

**Verification status across phases:**
- Phase 1: Plans 01-04 code PASS, Plan 05 hardware tests 6/6 PASS (multilingual still running)
- Phase 2: Verification chain PASS, 5 human verification items pending (real-device testing)
- Phase 3: Stages 1-3 PASS, Stage 4 (/mow:verify-work) and Stage 5 PENDING, visual verification never done
</context>

<next_action>
1. Wait for multilingual test to finish on device (~30-60 min from start)
2. Pull spike_results.json from device: adb pull /data/data/com.bittybot.bittybot/app_flutter/spike_results.json
3. Optionally run judge tooling
4. Merge mowismtest branch into master
</next_action>
